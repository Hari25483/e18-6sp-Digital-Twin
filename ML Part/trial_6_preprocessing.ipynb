{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def unzip_file(file_path, extract_path):\n",
    "    shutil.unpack_archive(file_path, extract_path)\n",
    "\n",
    "# Example usage\n",
    "zip_file_path = './trial_6-20230610T130222Z-001.zip'\n",
    "extract_to_path = 'content/'\n",
    "unzip_file(zip_file_path, extract_to_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['content/trial_6/sensorTower/2021-12-13\\\\10031.csv', 'content/trial_6/sensorTower/2021-12-13\\\\10032.csv', 'content/trial_6/sensorTower/2021-12-13\\\\10035.csv']\n",
      "['content/trial_6/sensorTower/2021-12-14\\\\10031.csv', 'content/trial_6/sensorTower/2021-12-14\\\\10032.csv', 'content/trial_6/sensorTower/2021-12-14\\\\10035.csv']\n",
      "['content/trial_6/sensorTower/2021-12-15\\\\10031.csv', 'content/trial_6/sensorTower/2021-12-15\\\\10032.csv', 'content/trial_6/sensorTower/2021-12-15\\\\10035.csv']\n",
      "['content/trial_6/sensorTower/2021-12-16\\\\10031.csv', 'content/trial_6/sensorTower/2021-12-16\\\\10032.csv', 'content/trial_6/sensorTower/2021-12-16\\\\10035.csv']\n",
      "['content/trial_6/sensorTower/2021-12-17\\\\10031.csv', 'content/trial_6/sensorTower/2021-12-17\\\\10032.csv', 'content/trial_6/sensorTower/2021-12-17\\\\10035.csv']\n",
      "['content/trial_6/sensorTower/2021-12-18\\\\10031.csv', 'content/trial_6/sensorTower/2021-12-18\\\\10032.csv', 'content/trial_6/sensorTower/2021-12-18\\\\10035.csv']\n",
      "['content/trial_6/sensorTower/2021-12-19\\\\10031.csv', 'content/trial_6/sensorTower/2021-12-19\\\\10032.csv', 'content/trial_6/sensorTower/2021-12-19\\\\10035.csv']\n",
      "['content/trial_6/sensorTower/2021-12-20\\\\10031.csv', 'content/trial_6/sensorTower/2021-12-20\\\\10032.csv', 'content/trial_6/sensorTower/2021-12-20\\\\10035.csv']\n",
      "['content/trial_6/sensorTower/2021-12-21\\\\10031.csv', 'content/trial_6/sensorTower/2021-12-21\\\\10032.csv', 'content/trial_6/sensorTower/2021-12-21\\\\10035.csv']\n",
      "['content/trial_6/sensorTower/2021-12-22\\\\10031.csv', 'content/trial_6/sensorTower/2021-12-22\\\\10032.csv', 'content/trial_6/sensorTower/2021-12-22\\\\10035.csv']\n",
      "['content/trial_6/sensorTower/2021-12-23\\\\10031.csv', 'content/trial_6/sensorTower/2021-12-23\\\\10032.csv', 'content/trial_6/sensorTower/2021-12-23\\\\10035.csv']\n",
      "['content/trial_6/sensorTower/2021-12-24\\\\10031.csv', 'content/trial_6/sensorTower/2021-12-24\\\\10032.csv', 'content/trial_6/sensorTower/2021-12-24\\\\10035.csv']\n",
      "['content/trial_6/sensorTower/2021-12-25\\\\10031.csv', 'content/trial_6/sensorTower/2021-12-25\\\\10032.csv', 'content/trial_6/sensorTower/2021-12-25\\\\10035.csv']\n",
      "['content/trial_6/sensorTower/2021-12-26\\\\10031.csv', 'content/trial_6/sensorTower/2021-12-26\\\\10032.csv', 'content/trial_6/sensorTower/2021-12-26\\\\10035.csv']\n",
      "['content/trial_6/sensorTower/2021-12-27\\\\10031.csv', 'content/trial_6/sensorTower/2021-12-27\\\\10032.csv', 'content/trial_6/sensorTower/2021-12-27\\\\10035.csv']\n",
      "['content/trial_6/sensorTower/2021-12-28\\\\10031.csv', 'content/trial_6/sensorTower/2021-12-28\\\\10032.csv', 'content/trial_6/sensorTower/2021-12-28\\\\10035.csv']\n",
      "['content/trial_6/sensorTower/2021-12-29\\\\10031.csv', 'content/trial_6/sensorTower/2021-12-29\\\\10032.csv', 'content/trial_6/sensorTower/2021-12-29\\\\10035.csv']\n",
      "['content/trial_6/sensorTower/2021-12-30\\\\10031.csv', 'content/trial_6/sensorTower/2021-12-30\\\\10032.csv', 'content/trial_6/sensorTower/2021-12-30\\\\10035.csv']\n",
      "['content/trial_6/sensorTower/2021-12-31\\\\10031.csv', 'content/trial_6/sensorTower/2021-12-31\\\\10032.csv', 'content/trial_6/sensorTower/2021-12-31\\\\10035.csv']\n",
      "['content/trial_6/sensorTower/2022-01-01\\\\10031.csv', 'content/trial_6/sensorTower/2022-01-01\\\\10032.csv', 'content/trial_6/sensorTower/2022-01-01\\\\10035.csv']\n",
      "['content/trial_6/sensorTower/2022-01-02\\\\10031.csv', 'content/trial_6/sensorTower/2022-01-02\\\\10032.csv', 'content/trial_6/sensorTower/2022-01-02\\\\10035.csv']\n",
      "['content/trial_6/sensorTower/2022-01-03\\\\10031.csv', 'content/trial_6/sensorTower/2022-01-03\\\\10032.csv', 'content/trial_6/sensorTower/2022-01-03\\\\10035.csv']\n",
      "['content/trial_6/sensorTower/2022-01-04\\\\10031.csv', 'content/trial_6/sensorTower/2022-01-04\\\\10032.csv', 'content/trial_6/sensorTower/2022-01-04\\\\10035.csv']\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the parent directory containing the date-named folders\n",
    "parent_directory = 'content/trial_6/sensorTower/'\n",
    "\n",
    "# List all the folders in the parent directory, sorted by name (date)\n",
    "folders = sorted([f for f in os.listdir(parent_directory) if os.path.isdir(os.path.join(parent_directory, f))])\n",
    "\n",
    "# Initialize an empty DataFrame to store the data\n",
    "dataframe = pd.DataFrame()\n",
    "\n",
    "# Loop through the folders in date order\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(parent_directory, folder)\n",
    "    \n",
    "    # Get the paths of the CSV files in the current folder\n",
    "    csv_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "    # Sort the CSV files by name (file1.csv, file2.csv, file3.csv)\n",
    "    csv_files = sorted(csv_files)\n",
    "    \n",
    "    print(csv_files)\n",
    "    \n",
    "    \n",
    "    # Load the CSV file into a DataFrame\n",
    "    external_weather = pd.read_csv('weather_data.csv')\n",
    "\n",
    "    # Combine the 'Date' and 'Time' columns into a single datetime column\n",
    "    external_weather['datetime'] = pd.to_datetime(external_weather['date'] + ' ' + external_weather['time'])\n",
    "\n",
    "    external_weather.drop([\"time\",\"date\"],axis=1,inplace=True)\n",
    "\n",
    "    external_weather.set_index('datetime', inplace=True)\n",
    "\n",
    "    merged_df = pd.merge(external_weather, new_df_hourly, on='datetime')\n",
    "\n",
    "    # Drop rows with any null values\n",
    "    merged_df.dropna(inplace=True)\n",
    "\n",
    "    merged_df.to_csv('data_set.csv')\n",
    "\n",
    "\n",
    "    \n",
    "    # # Read the CSV files into separate DataFrames for temperature, humidity, and light\n",
    "    # df_temperature = pd.read_csv(csv_files[0])\n",
    "    # df_humidity = pd.read_csv(csv_files[1])\n",
    "    # df_light = pd.read_csv(csv_files[2])\n",
    "    \n",
    "    # # Merge the DataFrames horizontally based on a common column if necessary\n",
    "    # # Assuming the CSV files have a common column like 'timestamp' to merge on\n",
    "    # merged_df = pd.merge(df_temperature, df_humidity, on='timestamp')\n",
    "    # merged_df = pd.merge(merged_df, df_light, on='timestamp')\n",
    "    \n",
    "    # # Append the merged DataFrame to the main DataFrame\n",
    "    # dataframe = dataframe.append(merged_df, ignore_index=True)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(dataframe)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
