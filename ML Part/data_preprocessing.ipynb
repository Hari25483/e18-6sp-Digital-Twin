{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ZPI0oe6BqLDF",
    "outputId": "5252059f-5c14-4331-f6fc-6ff1e429738d"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "base_url = \"http://agbc-fe.pdn.ac.lk/api/v1/data/?sensor=10008&date=\"\n",
    "\n",
    "start_date = pd.to_datetime(\"2020-10-22\")\n",
    "end_date = pd.to_datetime(\"2020-12-30\")\n",
    "\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq=\"D\")\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for date in tqdm(date_range, desc=\"Progress\", unit=\"day\"):\n",
    "    date_str = date.strftime(\"%Y-%m-%d\")\n",
    "    url = base_url + date_str\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        all_data.extend(data['data'])\n",
    "    except:\n",
    "        print(f\"Error: Could not retrieve data for date {date_str}\")\n",
    "        continue\n",
    "    \n",
    "\n",
    "df = pd.DataFrame(all_data, dtype=str)\n",
    "df.to_csv('dataws.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CXMbj9kvrn1H",
    "outputId": "56c43792-dfe6-4cc4-9654-1b01d336140f"
   },
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zBhqM74Brs51"
   },
   "outputs": [],
   "source": [
    "# drop rows with missing values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "joYskXyPrzA8"
   },
   "outputs": [],
   "source": [
    "# Drop duplicate rows\n",
    "df=df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "gEd3DbvksApo",
    "outputId": "a1a4440a-e2ab-4d00-9060-73107b549e57"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Replace '?' with NaN\n",
    "\n",
    "df.replace(' ?', np.nan, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "print(df.tail(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "xMtknm7U08g1",
    "outputId": "69988c3e-01f9-4285-c9dc-a8fce8e5b36b"
   },
   "outputs": [],
   "source": [
    "# Drop rows containing missing values\n",
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y3DnDwFzcrdM",
    "outputId": "93ea969a-939d-4c10-b47b-35828d743a44"
   },
   "outputs": [],
   "source": [
    "# Convert temperature columns to numeric\n",
    "df['temp1'] = pd.to_numeric(df['temp1'], errors='coerce')\n",
    "df['temp2'] = pd.to_numeric(df['temp2'], errors='coerce')\n",
    "df['temp3'] = pd.to_numeric(df['temp3'], errors='coerce')\n",
    "\n",
    "# Convert temperature columns to numeric\n",
    "df['humidity1'] = pd.to_numeric(df['humidity1'], errors='coerce')\n",
    "df['humidity2'] = pd.to_numeric(df['humidity2'], errors='coerce')\n",
    "df['humidity3'] = pd.to_numeric(df['humidity3'], errors='coerce')\n",
    "\n",
    "df['seqNo'] = pd.to_numeric(df['seqNo'], errors='coerce')\n",
    "\n",
    "# Calculate the average temperature\n",
    "df['average_internal_temp'] = df[['temp1', 'temp2', 'temp3']].mean(axis=1,skipna=True)\n",
    "\n",
    "# Calculate the average humidity\n",
    "df['average_internal_humidity'] = df[['humidity1', 'humidity2', 'humidity3']].mean(axis=1,skipna=True)\n",
    "\n",
    "# Create a new DataFrame with only the desired columns\n",
    "new_df = df[['seqNo','date','time','average_internal_temp', 'average_internal_humidity', 'light']]\n",
    "\n",
    "\n",
    "print(new_df.head())\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Create a Data frame for Internal Sensor 10008 data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the 'date' and 'time' columns into a single datetime column\n",
    "new_df['datetime'] = pd.to_datetime(new_df['date'] + ' ' + new_df['time'])\n",
    "# Set the 'time' column as the DataFrame index\n",
    "new_df.set_index('datetime', inplace=True)\n",
    "new_df.drop(['date', 'time','seqNo'], axis=1, inplace=True)\n",
    "# Resample the DataFrame using 'H' offset alias and select the first entry from each hour\n",
    "new_df_hourly = new_df.resample('H').first()\n",
    "\n",
    "# new_df_hourly.reset_index(inplace=True)\n",
    "# Print the resulting DataFrame\n",
    "print(new_df_hourly.head())\n",
    "\n",
    "new_df_hourly.to_csv('sensor10008.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Create a Data frame for External Environmental data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "external_weather = pd.read_csv('weather_data.csv')\n",
    "\n",
    "# Combine the 'Date' and 'Time' columns into a single datetime column\n",
    "external_weather['datetime'] = pd.to_datetime(external_weather['Date'] + ' ' + external_weather['Time'])\n",
    "\n",
    "external_weather.drop([\"Time\",\"Date\"],axis=1,inplace=True)\n",
    "\n",
    "external_weather.set_index('datetime', inplace=True)\n",
    "\n",
    "merged_df = pd.merge(external_weather, new_df_hourly, on='datetime')\n",
    "\n",
    "# Drop rows with any null values\n",
    "merged_df.dropna(inplace=True)\n",
    "\n",
    "merged_df.to_csv('data_set.csv')\n",
    "\n",
    "print(merged_df.head())\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "interpreter": {
   "hash": "ed69033dcf95bf03c49614e5fe4e96f21774bed12a1dae221247a7de4d30fa71"
  },
  "kernelspec": {
   "display_name": "Python 3.10.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
